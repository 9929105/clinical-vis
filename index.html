<!DOCTYPE html>
<html>
<head>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-46457317-11"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-46457317-11');
  </script>
  <title>ClinicalVis</title>
  <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">
  <link rel="stylesheet" href="https://code.getmdl.io/1.3.0/material.teal-cyan.min.css">
  <link href='http://fonts.googleapis.com/css?family=Roboto:300,300italic,400,400italic,500,500italic,700,700italic' rel='stylesheet' type='text/css'>
  <script defer src="https://code.getmdl.io/1.3.0/material.min.js"></script>
  <link rel="icon" href="./assets/favicon.png" type="image/png"/>
  <style type="text/css">

  body {
    font-family: 'Roboto', sans-serif;
  }

  .section-name {
    color: #202124;
    margin: 36px auto;
    padding: 36px auto;
  }

  .hero {
    min-height: 22vw;
  }
  .hero-banner {
    background-image: linear-gradient(
      rgba(255, 255, 255, 0),
      rgba(255, 255, 255, 0.57),
      rgba(255, 255, 255, 0.57),
      rgba(255, 255, 255, 0.77)
      ),url("./assets/CV-hero.png");
    background-size: contain;
    margin-bottom: 12px;
  }
  .mask {
    background: #ffffff;
    border-top: solid 1px #DADCE0;
  }
  .page-content{
    max-width: 1600px;
    margin: 0 auto;

    overflow-x: auto;
  }

  .big-title {
    padding: 64px 0px;
  }

  /*Typography*/
  .mdl-typography--display-4 {
    color: #FF9801;
  }

  .mdl-typography--display-1 {
    font-weight: 300;
    color: #3C4043;
    line-height: 1.4em;
  }

  .mdl-typography--headline {
    font-weight: 300;
    margin-bottom: 12px;
  }

  .mdl-typography--body-1 {
    font-family: 'Roboto', sans-serif;
  }

  .citation {
    vertical-align: super;
    font-size: smaller;
    text-decoration: underline;
    color: #5F6368;
    padding-left: 4px;
    line-height: 24px;
  }

  .inline {
    background: rgba(255,179,68,0.3);
    color: #202124;
    padding: 2px 2px 2px 4px;
    text-decoration: underline;
  }

  .inline:hover {
    color: #3C4043;
    background: rgba(255,179,68,0.7);

  }

  /*introduction*/
  .introduction-content {
    margin: 24px auto;
  }

  .tutorial-video {
    padding: 24px;
  }

  /*features*/
  .feature-list-item__content {
    padding: 12px;
    color: #5F6368;
  }

  .feature-list-item__content > .mdl-typography--display-1 {
    font-size: 24px;
    color: #5F6368;
    margin-bottom: 12px;
  }

  .feature-list-item__content > .mdl-typography--body-1 {
    font-size: 16px;
    color: #202124;
    font-weight: 300;
    font-family: 'Roboto', sans-serif;
  }

  /*feature images container*/
  .feature-list-item__image {
    width: 320px;
    height: 240px;
    border: solid 1px #DADCE0;
  }

  /*individual feature images*/
  .visualize-inference-feature > .feature-list-item__image {
    background-image: url('./assets/WIT-illustration-1.png');
    background-position: center;
    background-size: cover;
  }
  .edit-example-feature > .feature-list-item__image {
    background-image: url('./assets/WIT-illustration-2.png');
    background-position: center;
    background-size: cover;
  }
  .pd-plot-feature > .feature-list-item__image {
    background-image: url('./assets/WIT-illustration-3.png');
    background-position: center;
    background-size: cover;
  }
  .counterfactual-feature > .feature-list-item__image {
    background-image: url('./assets/WIT-illustration-4.png');
    background-position: center;
    background-size: cover;
  }
  .distance-feature-feature > .feature-list-item__image {
    background-image: url('./assets/WIT-illustration-5.png');
    background-position: center;
    background-size: cover;
  }
  .performance-feature > .feature-list-item__image {
    background-image: url('./assets/WIT-illustration-6.png');
    background-position: center;
    background-size: cover;
  }
  .fairness-feature > .feature-list-item__image {
    background-image: url('./assets/WIT-illustration-7.png');
    background-position: center;
    background-size: cover;
  }


  /*demo cards*/
  .page-section {
    padding: 48px 0;
  }
  .demo-section-title {
    margin-bottom: 24px;
  }
  .demo-card-wide.mdl-card {
    width: 512px;
    border: solid 1px #DADCE0;
    margin: 16px;
  }

  .demo-card-wide > .mdl-card__title {
    height: 176px;
  }

  .demo-card-wide > .mdl-typography--body-1 {
    font-size:  16px;
    color: #202124;
    font-weight: 300;
    font-family: 'Roboto', sans-serif;
    line-height: 28px;

  }

  .demo-title {
    color: #000000;
  }

  .demo-description {
    color: #3C4043;
  }
  /*demo card images*/

  .binary-classification-demo > .mdl-card__title {
    background-image: linear-gradient(
      rgba(255, 255, 255, 0),
      rgba(255, 255, 255, 0.57),
      rgba(255, 255, 255, 0.57),
      rgba(255, 255, 255, 0.77)
      ),
    url('./assets/over50k-bins.png');
    background-position: center;
    background-size: cover;
    border-bottom: solid 1px #DADCE0;
  }
  .image-binary-classification-demo > .mdl-card__title {
    background-image: linear-gradient(
      rgba(255, 255, 255, 0),
      rgba(255, 255, 255, 0.57),
      rgba(255, 255, 255, 0.57),
      rgba(255, 255, 255, 0.77)
      ),
    url('./assets/images-conf-matrix.png');
    background-position: center;
    background-size: cover;
    border-bottom: solid 1px #DADCE0;
  }
  .regression-demo > .mdl-card__title {
    background-image: linear-gradient(
      rgba(255, 255, 255, 0),
      rgba(255, 255, 255, 0.57),
      rgba(255, 255, 255, 0.57),
      rgba(255, 255, 255, 0.77)
      ),
    url('./assets/age-scatter.png');
    background-position: center;
    background-size: cover;
    border-bottom: solid 1px #DADCE0;
  }
  .multiclass-classification-demo > .mdl-card__title {
    background-image: linear-gradient(
      rgba(255, 255, 255, 0),
      rgba(255, 255, 255, 0.57),
      rgba(255, 255, 255, 0.57),
      rgba(255, 255, 255, 0.77)
      ),
    url('./assets/iris-scatter.png');
    background-position: center;
    background-size: cover;
    border-bottom: solid 1px #DADCE0;
  }


  /*to organize */
  .chip {
    padding: 0 0 16px 16px;
  }
  .mdl-chip {
    background: #ffffff;
    border: solid 1px #DADCE0;
    color: #80868B;
  }
  /*.mdl-grid {
    margin-bottom: 120px;
    }*/
    .icon-style {
      margin: auto 4px;
      font-size: 1.2em;
    }
    .button-style {
      margin: auto 6px;
    }
    .button-style > .icon-style {
      margin: auto 4px auto 8px;
      font-size: 1.6em;
    }

  </style>
</head>

<body>
  <div class="mdl-layout mdl-js-layout mdl-layout--fixed-header">
    <header class="mdl-layout__header">
      <div class="mdl-layout__header-row">
        <!-- Title -->
        <span class="mdl-layout__title">ClinicalVis</span>
        <!-- Add spacer, to align navigation to the right -->
        <div class="mdl-layout-spacer"></div>
        <!-- Navigation. We hide it in small screens. -->
        <nav class="mdl-navigation mdl-layout--large-screen-only">
          <a class="mdl-navigation__link" href="./index.html">Home</a>
          <a class="mdl-navigation__link" href="./index.html#intro">Introduction</a>
          <a class="mdl-navigation__link" href="./index.html#features">Features</a>
          <a class="mdl-navigation__link" href="./index.html#demos">Demos</a>
          <a class="mdl-navigation__link" href="./index.html#about">About</a>
          <a class="mdl-navigation__link" href="./index.html#references">References</a>
<!--           <a class="mdl-navigation__link" href="./ai-fairness.html">AI Fairness</a> -->
          <a class="mdl-navigation__link button-style mdl-typography--text-uppercase" href="https://ai.google/research/teams/brain/pair" target="-_blank">
            <i class="material-icons icon-style">open_in_new</i>
            <span>PAIR</span>
          </a>
          <a class="mdl-navigation__link button-style mdl-typography--text-uppercase" href="https://github.com/tensorflow/tensorboard/tree/master/tensorboard/plugins/interactive_inference" target="-_blank">
            <i class="material-icons icon-style">link</i>
            <span>Github</span>
          </a>
        </nav>
      </div>
    </header>
    <div class="mdl-layout__drawer">
      <span class="mdl-layout-title">ClinicalVis</span>
      <nav class="mdl-navigation">
        <a class="mdl-navigation__link" href="./index.html">Home</a>
        <a class="mdl-navigation__link" href="./index.html#intro">Introduction</a>
        <a class="mdl-navigation__link" href="./index.html#features">Features</a>
        <a class="mdl-navigation__link" href="./index.html#demos">Demos</a>
        <a class="mdl-navigation__link" href="./index.html#about">About</a>
        <a class="mdl-navigation__link" href="./index.html#references">References</a>
<!--         <a class="mdl-navigation__link" href="./ai-fairness.html">AI Fairness</a> -->
        <hr>
<!--         <a class="mdl-navigation__link" href="http://ai.googleblog.com/2018/09/the-what-if-tool-code-free-probing-of.html" target="_blank">Read the blog post</a> -->
        <a class="mdl-navigation__link" href="https://ai.google/research/teams/brain/pair">About PAIR</a>
        <a class="mdl-navigation__link" href="https://github.com/tensorflow/tensorboard/tree/master/tensorboard/plugins/interactive_inference">Github</a>
        <a class="mdl-navigation__link" href="https://pair-code.github.io/facets/" target="-_blank">
          <i class="material-icons icon-style">star</i>
          <span>Facets</span>
        </a>
        <a class="mdl-navigation__link" href="https://js.tensorflow.org" target="-_blank">
          <i class="material-icons icon-style">star</i>
          <span>TensorFlow.js</span>
        </a>
      </nav>
    </div>

    <main class="mdl-layout__content hero-banner">
      <div class="page-content hero">
        <div class="mdl-grid">
          <div class="mdl-cell mdl-cell--11-col mdl-cell--1-offset mdl-cell--7-col-tablet mdl-cell--1-offset-tablet mdl-cell--4-col-phone section-name big-title">
            <div class="mdl-typography--display-4 what-if">ClinicalVis</div>
            <div class="mdl-typography--display-1 tagline">A visualization-based prototype system <br>to explore the interaction of healthcare providers and Electronic Health Records
            </div>
          </div>
        </div>
      </div>
      <div class="mask">
        <div class="page-content">
          <div class="intro mdl-grid" id="intro">
            <div class="mdl-cell mdl-cell--5-col mdl-cell--2-offset mdl-cell--6-col-tablet mdl-cell--1-offset-tablet mdl-cell--4-col-phone introduction-content ">
              <div class="mdl-typography--headline">Abstract</div><br>
              <div class="mdl-typography--body-1">Making decisions about what clinical tasks to prepare for is multi-factored, and especially challenging in intensive care environments where resources must be balanced with patient needs. Electronic health records (EHRs) are a rich data source, but are task-agnostic and can be difficult to use as summarizations of patient needs for a specific task, such as ``could this patient need a ventilator tomorrow?'' In this paper, we introduce \textit{ClinicalVis}, an open-source EHR visualization-based prototype system for task-focused design evaluation of interactions between healthcare providers (HCPs) and EHRs. We situate ClinicalVis in a task-focused proof-of-concept design study targeting these interactions with real patient data. We conduct an empirical study of 14 HCPs, and discuss our findings on usability, accuracy, preference, and confidence in treatment decisions. We also present design implications that our findings suggest for future EHR interfaces, the presentation of clinical data for task-based planning, and evaluating task-focused HCP/EHR interactions in practice.</div>
            </div>
            <div class="mdl-cell mdl-cell--5-col mdl-cell--1-offset mdl-cell--4-col-tablet mdl-cell--2-offset-tablet mdl-cell--4-col-phone tutorial-video ">
              <iframe width="560" height="315" src="https://www.youtube.com/embed/hpYl8WLYeKo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
            </div>
          </div>

          <div class="page-section features mdl-grid" id="features">
            <div class="mdl-cell mdl-cell--11-col mdl-cell--1-offset mdl-cell--7-col-tablet mdl-cell--1-offset-tablet mdl-cell--4-col-phone mdl-typography--display-1 section-name">
              About ClinicalVis 
            </div>

            <div class="feature-list-item mdl-cell mdl-cell--10-col mdl-cell--1-offset mdl-cell--8-col-tablet mdl-cell--4-col-phone">
              <div class="mdl-grid mdl-grid--nesting visualize-inference-feature">
                <div class="feature-list-item__image mdl-cell mdl-cell--4-col mdl-cell--4-col-tablet"></div>
                <div class="feature-list-item__content mdl-cell mdl-cell--6-col mdl-cell--4-col-tablet">
                  <div class="feature-list-item__title mdl-typography--display-1">What is ClinicalVis?
                  </div>
                  <div class="feature-list-item__text mdl-typography--body-1">
                    ClinicalVis is an open-source visualization-based proof of concept for EHRs. Designed as content-idependent but (data) structure-dependent, ClinicalVis enables rapid information assimliation and supports the inference of insights from large amounts of data, specifically for clinical preparedness. 
                    <br><br>ClinicalVis was designed keeping in mind known and observed HCP workflows, and we use simple visualizations that can be easily read with little onboarding. It is is scalable to include a range of variables, and can be used more generally to investigate during- and post-task clinical usage of ICU EHRs. Try out our <a class="inline" id="#demo">demo</a>!
                  </div>
                </div>
              </div>
            </div>

            <div class="feature-list-item mdl-cell mdl-cell--10-col mdl-cell--1-offset mdl-cell--8-col-tablet mdl-cell--4-col-phone">
              <div class="mdl-grid mdl-grid--nesting edit-example-feature">
                <div class="feature-list-item__image mdl-cell mdl-cell--4-col mdl-cell--4-col-tablet "></div>
                <div class="feature-list-item__content mdl-cell mdl-cell--6-col  mdl-cell--4-col-tablet ">
                  <div class="feature-list-item__title mdl-typography--display-1">Why did we build it?
                  </div>
                  <div class="feature-list-item__text mdl-typography--body-1">
                   There is a strong body of prior work on designing visualization-based systems and prototypes that support teamwork in healthcare coordination [1] and  patient-level healtcare management. There are many commercial EHR visualizations that are promising, but duplicating the evaluations conducted on closed-source systems are difficult, and experiments on care planning in a task-oriented setting are hard to reproduce.<br><br>We built and evaluated ClinicalVis to add to the relatively small body of research on evaluating HCP interactions with EHR visualizations in a realistic task-focused scenario. 
                  </div>
                </div>
              </div>
            </div>

            <div class="feature-list-item mdl-cell mdl-cell--10-col mdl-cell--1-offset mdl-cell--8-col-tablet mdl-cell--4-col-phone">
              <div class="mdl-grid mdl-grid--nesting pd-plot-feature">
                <div class="feature-list-item__image mdl-cell mdl-cell--4-col  mdl-cell--4-col-tablet "></div>
                <div class="feature-list-item__content mdl-cell mdl-cell--6-col  mdl-cell--4-col-tablet ">
                  <div class="feature-list-item__title mdl-typography--display-1">How did we evaluate ClinicalVis? 
                  </div>
                  <div class="feature-list-item__text mdl-typography--body-1">
                    We conducted an empirical evaluation of HCP-EHR interaction with ClinicalVis and the baseline prototype in a mixed-methods, task-focused user study centered around clinical care planning a remote eICU scenario. The baseline prototype was designed to emulate commercially available EHR softwares, and participating HCPs engaged with EHRs sourced from the MIMIC-III database. <br><br> Read the paper as a <a class="inline">PDF</a> or as a detailed summary <a class="inline">online</a>. 
                  </div>
                </div>
              </div>
            </div>

            <div class="feature-list-item mdl-cell mdl-cell--10-col mdl-cell--1-offset mdl-cell--8-col-tablet mdl-cell--4-col-phone">
              <div class="mdl-grid mdl-grid--nesting pd-plot-feature">
                <div class="feature-list-item__image mdl-cell mdl-cell--4-col  mdl-cell--4-col-tablet "></div>
                <div class="feature-list-item__content mdl-cell mdl-cell--6-col  mdl-cell--4-col-tablet ">
                  <div class="feature-list-item__title mdl-typography--display-1">How can you use it>
                  </div>
                  <div class="feature-list-item__text mdl-typography--body-1">
                    The design implications of our work suggest that modeling clinical data for decision support should include elements to guide clinical use. We believe that ClinicalVis can open up avenues for the rigorous evaluation of interactions between clinicians and patient data to best improve aspects of healthcare delivery.<br><br> To that end, we have open-sourced ClinicalVis and are publishing our findings, hoping that you can take our visualization and apply it in your own research. 
                  </div>
                </div>
              </div>
            </div>

<!--             <div class="feature-list-item mdl-cell mdl-cell--10-col mdl-cell--1-offset mdl-cell--8-col-tablet mdl-cell--4-col-phone">
              <div class="mdl-grid mdl-grid--nesting counterfactual-feature">
                <div class="feature-list-item__image mdl-cell mdl-cell--4-col mdl-cell--4-col-tablet "></div>
                <div class="feature-list-item__content mdl-cell mdl-cell--6-col  mdl-cell--4-col-tablet ">
                  <div class="feature-list-item__title mdl-typography--display-1">Explore counterfactual examples
                  </div>
                  <div class="feature-list-item__text mdl-typography--body-1">
                    Seek out the most similar example of a different classification for any datapoint for classification models along L1 and L2 distances calculated using the distribution of feature values across all loaded examples. WIT highlights the delta between the initial example and its counterfactual<a class="citation" href=#ref2 id="cite1">[1]</a><span class="mdl-tooltip mdl-tooltip--right" for="cite1">Wachter, S., Mittelstadt, B., & Russell, C. (2017). Counterfactual explanations without opening the black box: Automated decisions and the GDPR.</span>.
                  </div>
                </div>
              </div>
            </div> -->

<!--             <div class="feature-list-item mdl-cell mdl-cell--10-col mdl-cell--1-offset mdl-cell--8-col-tablet mdl-cell--4-col-phone">
              <div class="mdl-grid mdl-grid--nesting distance-feature-feature">
                <div class="feature-list-item__image mdl-cell mdl-cell--4-col mdl-cell--4-col-tablet "></div>
                <div class="feature-list-item__content mdl-cell mdl-cell--6-col  mdl-cell--4-col-tablet ">
                  <div class="feature-list-item__title mdl-typography--display-1">Arrange examples by similarity
                  </div>
                  <div class="feature-list-item__text mdl-typography--body-1">
                    Create distance features from a selected datapoint using either L1 or L2 distances and apply it to your visualizations for further analysis.
                  </div>
                </div>
              </div>
            </div> -->

<!--             <div class="feature-list-item mdl-cell mdl-cell--10-col mdl-cell--1-offset mdl-cell--8-col-tablet mdl-cell--4-col-phone">
              <div class="mdl-grid mdl-grid--nesting performance-feature">
                <div class="feature-list-item__image mdl-cell mdl-cell--4-col mdl-cell--4-col-tablet "></div>
                <div class="feature-list-item__content mdl-cell mdl-cell--6-col  mdl-cell--4-col-tablet ">
                  <div class="feature-list-item__title mdl-typography--display-1">View confusion matrices and ROC curves
                  </div>
                  <div class="feature-list-item__text mdl-typography--body-1">
                    For binary classification models and examples that include a feature describing the true label, explore model performance interactively using thresholds, <a class="inline" href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic" target='_blank'>ROC curves</a>, numeric <a class="inline" href="https://en.wikipedia.org/wiki/Confusion_matrix" target='_blank'>confusion matrices</a> and cost ratios.
                  </div>
                </div>
              </div>
            </div> -->

<!--             <div class="feature-list-item mdl-cell mdl-cell--10-col mdl-cell--1-offset mdl-cell--8-col-tablet mdl-cell--4-col-phone">
              <div class="mdl-grid mdl-grid--nesting fairness-feature">
                <div class="feature-list-item__image mdl-cell mdl-cell--4-col mdl-cell--4-col-tablet "></div>      
                <div class="feature-list-item__content mdl-cell mdl-cell--6-col  mdl-cell--4-col-tablet ">
                  <div class="feature-list-item__title mdl-typography--display-1 ">Test algorithmic fairness constraints
                  </div>
                  <div class="feature-list-item__text mdl-typography--body-1">
                    For binary classification models, slice your dataset into subgroups and explore the effect of different algorithmic fairness constraints with the push of a button, such as "equality of opportunity"<a class="citation" href=#ref2 id="cite2">[2]</a><span class="mdl-tooltip mdl-tooltip--right" for="cite2">Hardt, M., Price, E., & Srebro, N. (2016). Equality of opportunity in supervised learning. In Advances in neural information processing systems (pp. 3315-3323).</span>, for your model on those subgroups.
                    <br><br>
                    Read more about investigating algorithmic fairness on the What-If Tool in <a class="inline" href="./ai-fairness.html" target="_blank">this article</a> by <a class="inline" href="http://www.hyperorg.com/speaker/bio.html" target="_blank">David Weinberger</a>.
                  </div>
                </div>
              </div>
            </div> -->

          </div>
<!-- 
          <div class="demos mdl-grid mdl-grid--no-spacing page-section" id="demos">
            <div class="mdl-cell mdl-cell--11-col mdl-cell--1-offset mdl-cell--7-col-tablet mdl-cell--1-offset-tablet mdl-typography--display-1 section-name demo-section-title">
              Demo ClinicalVis
            </div>
            <div class="mdl-cell mdl-cell--4-col mdl-cell--1-offset mdl-cell--7-col-tablet mdl-cell--1-offset-tablet mdl-cell--4-col-phone demo-card-cell">
              <div class="mdl-card demo-card-wide binary-classification-demo">
                <div class="mdl-card__title demo-card-title">
                  <h2 class="mdl-card__title-text demo-title demo-content">Income Classification</h2>
                </div>
                <div class="mdl-card__supporting-text demo-description demo-content mdl-typography--body-1"> This binary classification model predicts whether a person earns more than $50k a year based on their census information<a class="citation" href=#ref3 id="cite3a">[3]</a><span class="mdl-tooltip--top mdl-tooltip" for="cite3a">Fisher, R. A. UCI Machine Learning Repository. Irvine, CA: University of California, School of Information and Computer Science.</span>. Discover how different features affect the model's predictions.
                </div>
                <div class="chip">
                  <span class="mdl-chip">
                    <span class="mdl-chip__text">Binary Classification</span>
                  </span>
                  <span class="mdl-chip">
                    <span class="mdl-chip__text">Numeric Data</span>
                  </span>
                  <span class="mdl-chip">
                    <span class="mdl-chip__text">Categorical Data</span>
                  </span>
                </div>
                <div class="mdl-card__actions mdl-card--border">
                  <a class="mdl-button mdl-button--colored mdl-js-button mdl-js-ripple-effect" href="uci.html" target="_blank"> Go to demo </a>
                </div>
              </div>
            </div> -->

<!--             <div class="mdl-cell mdl-cell--4-col mdl-cell--1-offset mdl-cell--7-col-tablet mdl-cell--1-offset-tablet mdl-cell--4-col-phone demo-card-cell">
              <div class="mdl-card demo-card-wide regression-demo">
                <div class="mdl-card__title demo-card-title">
                  <h2 class="mdl-card__title-text demo-title demo-content">Age Prediction</h2>
                </div>
                <div class="mdl-card__supporting-text demo-description demo-content mdl-typography--body-1"> This regression model predicts a person's age from their census information<a class="citation" href=#ref3 id="cite3b">[3]</a><span class="mdl-tooltip--top mdl-tooltip" for="cite3b">Fisher, R. A. UCI Machine Learning Repository. Irvine, CA: University of California, School of Information and Computer Science.</span>. Slice data and explore inference results, such as aggregated inference error measures across different subgroups. 
                </div>
                <div class="chip">
                  <span class="mdl-chip">
                    <span class="mdl-chip__text">Regression Model</span>
                  </span>
                  <span class="mdl-chip">
                    <span class="mdl-chip__text">Numeric Data</span>
                  </span>
                  <span class="mdl-chip">
                    <span class="mdl-chip__text">Categorical Data</span>
                  </span>
                </div>
                <div class="mdl-card__actions mdl-card--border">
                  <a class="mdl-button mdl-button--colored mdl-js-button mdl-js-ripple-effect" href="age.html" target="_blank"> Go to demo </a>
                </div>
              </div>
            </div> -->

<!--             <div class="mdl-cell mdl-cell--4-col mdl-cell--1-offset mdl-cell--7-col-tablet mdl-cell--1-offset-tablet mdl-cell--4-col-phone demo-card-cell">
              <div class="mdl-card demo-card-wide image-binary-classification-demo">
                <div class="mdl-card__title demo-card-title">
                  <h2 class="mdl-card__title-text demo-title demo-content">Smile Detection</h2>
                </div>
                <div class="mdl-card__supporting-text demo-description demo-content mdl-typography--body-1">This binary classification model predicts whether an image contains a smiling face<a class="citation" href=#ref5 id="cite5">[5]</a><span class="mdl-tooltip--top mdl-tooltip" for="cite5">Liu, Z, Luo, P, Wang, X, Tang, X. Deep Learning Face Attributes in the Wild. Proceedings of International Conference on Computer Vision (ICCV) 2015.</span>. Can you figure out what group was missing from the training data, resulting in a biased model?
                </div>
                <div class="chip">
                  <span class="mdl-chip">
                    <span class="mdl-chip__text">Binary Classification</span>
                  </span>
                  <span class="mdl-chip">
                    <span class="mdl-chip__text">Image Data</span>
                  </span>
                </div>
                <div class="mdl-card__actions mdl-card--border">
                  <a class="mdl-button mdl-button--colored mdl-js-button mdl-js-ripple-effect" href="image.html" target="_blank"> Go to demo </a>
                </div>
              </div>
            </div>
 -->
<!--             <div class="mdl-cell mdl-cell--4-col mdl-cell--1-offset mdl-cell--7-col-tablet mdl-cell--1-offset-tablet mdl-cell--4-col-phone demo-card-cell">
              <div class="mdl-card demo-card-wide multiclass-classification-demo">
                <div class="mdl-card__title demo-card-title">
                  <h2 class="mdl-card__title-text demo-title demo-content">Iris Flower</h2>
                </div>
                <div class="mdl-card__supporting-text demo-description demo-content mdl-typography--body-1"> This multi-class classification model predicts flower type from plant measurements<a class="citation" href=#ref4 id="cite4">[4]</a><span class="mdl-tooltip mdl-tooltip--top" for="cite4">Lichman, M. UCI Machine Learning Repository. Irvine, CA: University of California, School of Information and Computer Science.</span>. Look at the correlations between different features and flower type.
                </div>
                <div class="chip">
                  <span class="mdl-chip">
                    <span class="mdl-chip__text">Multiclass Classification</span>
                  </span>
                  <span class="mdl-chip">
                    <span class="mdl-chip__text">Numeric Data</span>
                  </span>
                </div>
                <div class="mdl-card__actions mdl-card--border">
                  <a class="mdl-button mdl-button--colored mdl-js-button mdl-js-ripple-effect" href="iris.html" target="_blank"> Go to demo </a>
                </div>
              </div>
            </div> -->

          </div>
          <div class="about mdl-grid page-section" id="about">
            <div class="mdl-cell mdl-cell--3-col mdl-cell--1-offset mdl-typography--display-1 mdl-cell--2-col-tablet">Authors & Affiliations</div>
            <div class=" mdl-cell mdl-cell--1-offset mdl-cell--5-col mdl-typography--body-1 mdl-cell--6-col-tablet ">
            	<br><span class="mdl-typography--headline">Authors & Affiliations </span><br>
              Marzyeh Ghassemi - University of Toronto, Verily<br>
              Mahima Pushkarna - Google AI<br>
              James Wexler - Google AI<br>
              Jesse Johnson - Sanofi Genzyme, Verily<br>
              Paul Varghese - Verily<br>
              <br>
              <br><span class="mdl-typography--headline">PAIR </span><br>
              The <a class="inline" href="https://www.google.ai/pair" target='_blank'>People + AI Research initiative (PAIR)</a> brings together researchers across <a class='inline' href='https://ai.google' target='_blank'>Google</a> to study and redesign the ways people interact with AI systems. We focus on the &quot;human side&quot; of AI: the relationship between users and technology, the new applications it enables, and how to make it broadly inclusive. Our goal isn't just to publish research; we're also releasing open source tools for researchers and other experts to use.
              <br><br><span class="mdl-typography--headline">Acknowledgements</span><br>
              ClinicalVis was a collaborative effort between PAIR and Verily. We would like to thank all our colleagues and study participants that piloted the visualization and provided valuable feedback.
	            <br><br><span class="mdl-typography--headline"><b>This is not an official Google product</b></span><br>
            </div>
          </div>
          <hr>
          <div class="references mdl-grid page-section" id="references">
            <div class="mdl-cell mdl-cell--3-col  mdl-cell--1-offset mdl-typography--display-1 mdl-cell--2-col-tablet">References</div>
            <div class=" mdl-cell mdl-cell--1-offset mdl-cell--5-col mdl-cell--6-col-tablet ">
              <div class="mdl-typography--body-1" id="ref1"><a class="citation" href=#features>[1]</a> Wachter, S., Mittelstadt, B., & Russell, C. (2017). Counterfactual explanations without opening the black box: Automated decisions and the GDPR.<a class="inline" href="https://arxiv.org/abs/1711.00399" target="_blank">https://arxiv.org/abs/1711.00399</a>
              </div>
              <br>
              <div class="mdl-typography--body-1" id="ref2"><a class="citation" href=#features>[2]</a> Hardt, M., Price, E., & Srebro, N. (2016). Equality of opportunity in supervised learning. In Advances in neural information processing systems (pp. 3315-3323). <a class="inline" href="https://arxiv.org/abs/1610.02413" target="_blank">https://arxiv.org/abs/1610.02413</a>
              </div>
              <br>
              <div class="mdl-typography--body-1" id="ref3"><a class="citation" href=#demos>[3]</a> Fisher, R. A. UCI Machine Learning Repository. Irvine, CA: University of California, School of Information and Computer Science. <a class="inline" href="http://archive.ics.uci.edu/ml/datasets/Census+Income" target="_blank">http://archive.ics.uci.edu/ml/datasets/Census+Income</a>
              </div>
              <br>
              <div class="mdl-typography--body-1" id="ref4">
                <a class="citation" href=#demos>[4]</a> Lichman, M. UCI Machine Learning Repository. Irvine, CA: University of California, School of Information and Computer Science. <a class="inline" href="https://archive.ics.uci.edu/ml/datasets/iris" target="_blank">https://archive.ics.uci.edu/ml/datasets/iris</a>.
              </div>
              <br>
              <div class="mdl-typography--body-1" id="ref5">
                <a class="citation" href=#demos>[5]</a> Liu, Z, Luo, P, Wang, X, Tang, X. Deep Learning Face Attributes in the Wild. Proceedings of International Conference on Computer Vision (ICCV) 2015. <a class="inline" href="http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html" target="_blank">http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html</a>
              </div>
            </div>
          </div>
        </div>
      </div>
    </main>
  </div>
</body>
</html>